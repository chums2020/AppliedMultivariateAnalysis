The file, Set_8.csv, contains the data from a follow-up to the job search study. The file contains GRE scores (Verbal + Quantitative) upon entering graduate school, number of publications while in graduate school, length of time to complete the Ph.D. (in years), and the outcome of the job search (1=no interviews, 2=got a job, 3=interviews but no job). The variable, sample, divides the sample into two random halves. Analyze the data from sample=1 using discriminant analysis to determine how best to predict job search outcome. Use sample=2 for cross-validation. Answer the following questions.
1. How many discriminant functions are significant?
2. Comment on their relative “importance.”
3. How would you interpret the(se) function(s)?
4. How well are the original cases classified?
(a) Calculate a significance test that compares the classification to what would be expected by chance.
(b) Calculate Klecka’s tau.
5. (a) What is the most common type of misclassification?
(b) Speculate about what might account for this misclassification?
(c) What additional predictor(s) might this suggest for future analysis?
6. How well are the cases classified using the jackknife (leave-one-out) procedure?
7. How well are cases in the cross-validation sample classified?
8. Based on the analysis, what advice would you give to a student thinking about a career in academia?


Data <- read.table('C:/Users/Claire/Documents/Applied Multivariate Analysis/Homework10/Set_8.csv', sep=',',header=TRUE)
library(psych)
library(cluster)
library(sciplot)
library(ggplot2)
library(DiscriMiner)
library(candisc)
library(sciplot)
library(MASS)
library(MVN)
library(ade4)
library(biotools)
library(klaR)
library(boot)

Data1 <- Data[Data$sample ==1,]
par(mfrow = c(1,1))
boxplot(Data1$gre~Data1$outcome, horizontal = TRUE, main = list("GRE"),xlab = list("Value"), ylab = list("Group") )
boxplot(Data1$pubs ~ Data1$outcome, horizontal = TRUE, main = list("Publication Numbers"),xlab = list("Value"), ylab = list("Group") )
boxplot(Data1$years ~ Data1$outcome, horizontal = TRUE, main = list("Years"),xlab = list("Value"), ylab = list("Group") )

LDA1 <- lda(outcome ~ gre + pubs + years, data = Data1)
MLM1 <- lm(cbind(gre, pubs, years)~ as.factor(outcome), data = Data1)
CDA1 <- candisc(MLM1, data = Data1)

CDA1$coeffs.std  #weight, based on standardized variables
CDA1$structure   #correlation b/w each variable and each function

CDA1

linDA <-linDA(Data1[, 1:3], Data1[,4], prior = NULL, validation = NULL, learn = NULL, test = NULL, prob = FALSE)
linDA$confusion
linDA$error_rate
T <- linDA$confusion #confusion matrix
MO1 <- sum(T[1,])
MO2 <- sum(T[2,])
MO3 <- sum(T[3,])
MP1 <- MO1
MP2 <- MO2
MP3 <- MO3
N <- sum(T)
O <- sum(diag(T)) #observed agreement 
E <- (MO1*MP1/N) + (MO2*MP2/N) + (MO3*MP3/N) #expected agreement

#Calculate t test
e <- E/N
t = (O - E)/sqrt(N*e*(1-e)) #t test
t

#Calculate Klecka’s tau
Tau <- (O-E)/(N-E)
Tau

Jack1 <- lda(outcome ~ gre + pubs + years, data = Data1, CV = TRUE)
table(Original = Data1$outcome, Predicted = Jack1$class)
Proportion_of_Correct_classification <- sum(diag(table(Original = Data1$outcome, Predicted = Jack1$class)))/sum(table(Original = Data1$outcome, Predicted = Jack1$class))
Proportion_of_Correct_classification

training_sample <- which(Data$sample ==1)
Data_train <-lda(outcome ~ gre + pubs + years, data = Data1, CV = FALSE, subset = training_sample)
Predict <- predict(Data_train, newdata = Data[-training_sample,])
Original <- as.data.frame(Data[-training_sample, 4])
Cross <- cbind(Original, Predict$class)
names(Cross) <- c("Original_Outcome", "Predicted_Outcome")
table(Original = Cross$Original_Outcome, Predicted = Cross$Predicted_Outcome)

Proportion_of_Correct_classification <- sum(diag(table(Original = Cross$Original_Outcome, Predicted = Cross$Predicted_Outcome)))/sum(table(Original = Cross$Original_Outcome, Predicted = Cross$Predicted_Outcome))
Proportion_of_Correct_classification
